{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5.1 - Curation-Keywords\n",
    "\n",
    "This notebook implements the workflow defined in:\n",
    "\n",
    "[Curating keywords](https://gitlab.gwdg.de/sshoc/marketplace-curation/-/issues/1#note_71056) GitLab issue\n",
    "\n",
    "The notebook works as follows:\n",
    "\n",
    "0. Imports external libraries and loads the MP dataset and the google sheet\n",
    "2. Updates keywords on MP as follows:\n",
    "    1. Looks for vocabulary terms with the value from the column *Keyword to map*\n",
    "    2. Looks for the term in the column *Map to*\n",
    "    3. Goes through all MP items to look for the *keywords-to-map* in the keyword-dynamic-property\n",
    "    4. Replaces the  the *keywords-to-map* in the MP dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Requirements to run this notebook\n",
    "\n",
    "This section gives all the relevant information to \"interact\" with the MP data.\n",
    "\n",
    "### 0.1 libraries\n",
    "*There are a number of external libraries needed to run the notebook* \n",
    "\n",
    "*Furthermore, a dedicated SSH Open Marketplace library - sshmarketplacelib - with customised functions has been created and can be imported using the python import commands.* \n",
    "\n",
    "*Below the libraries import needed to run this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "#import the MarketPlace Library \n",
    "from sshmarketplacelib import MPData as mpd\n",
    "from sshmarketplacelib import  eval as eva, helper as hel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Get the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the MarketPlace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpdata = mpd()\n",
    "df_tool_flat =mpdata.getMPItems (\"toolsandservices\", True)\n",
    "df_publication_flat =mpdata.getMPItems (\"publications\", True)\n",
    "df_trainingmaterials_flat =mpdata.getMPItems (\"trainingmaterials\", True)\n",
    "df_workflows_flat =mpdata.getMPItems (\"workflows\", True)\n",
    "df_datasets_flat =mpdata.getMPItems (\"datasets\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of keywords from the [gsheet](https://docs.google.com/spreadsheets/d/1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sheet_id = '1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA'\n",
    "sheet_name = 'Mappings'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df_keywords=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_keyword=df_keywords.groupby(['Keyword to map'])['Map to'].apply(list).reset_index(name='Maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_keyword.iloc[40:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *getMPConcepts()* is a custom function that uses the API entry: \n",
    "\n",
    "GET https://marketplace-api.sshopencloud.eu/api/concept-search?perpage=100&q=URI\n",
    "\n",
    "to get all the *concepts* from the MarketPlace dataset. \n",
    "\n",
    "**Note that this function may require a long execution time**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts=mpdata.getMPConcepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils=hel.Util()\n",
    "resultfields=['persistentId', 'MPUrl', 'category', 'label', 'type.code', 'type.label', 'concept.code', 'concept.label', 'concept.uri', 'concept.vocabulary.scheme']\n",
    "udf_alprop=utils.getAllPropertiesBySources()\n",
    "udf_alprop=udf_alprop.loc[ : ,resultfields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_alprop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_keyword.iloc[70:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Update keywords\n",
    "\n",
    "The function *getMPKeywordProperies(mKey)* used below is a custum function that uses the API entry \n",
    "\n",
    "    GET https://marketplace-api.sshopencloud.eu/api/concept-search?types=keyword&q=VALUE\n",
    "\n",
    "and returns the vocabulary terms for *mKey*.  \n",
    "\n",
    "The returned dataset is filtered to individuate those values coming from the vocabulary *sshoc-keyword* (vocabulary[code]=sshoc-keyword).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "selectedItems=pd.DataFrame()\n",
    "#df_vocterms=pd.DataFrame()\n",
    "for rown, row in df_grouped_keyword.iterrows():\n",
    "    \n",
    "    uk=df_grouped_keyword.iloc[rown]['Keyword to map']\n",
    "    myKeys=df_grouped_keyword.iloc[rown]['Maps']\n",
    "    #df_vocterms=pd.DataFrame()\n",
    "    jsonmapto=[]\n",
    "    filterList={}\n",
    "    for myKey in myKeys:\n",
    "        myKey=myKey.strip()\n",
    "        df_vocterms=mpdata.getMPKeywordProperties(myKey.strip())\n",
    "        #print (f'n. vocabulary terms: {df_vocterms.shape[0]}')\n",
    "        print(f'***** checking {uk}, {myKey}')\n",
    "        if (df_vocterms.empty):\n",
    "            print (f\"#####  No vocabulary terms found for {myKey[0]}\")\n",
    "            continue;\n",
    "        df_vocterms.loc[:]=df_vocterms.loc[(df_vocterms.vocabulary=={'code': 'sshoc-keyword'}), ]\n",
    "    \n",
    "        #The set of vocabulary terms is filterd to individuate those with the exact match (case-insensitive) \n",
    "        df_vocterms=df_vocterms.loc[(df_vocterms.code).str.replace(' %3E ', ' > ').str.lower()==myKey.lower()]\n",
    "\n",
    "        #Search for the one concept that has in the uri column the value of the Map to. There should be only one such concept.\n",
    "    \n",
    "   \n",
    "        df_mapto=df_concepts.loc[(df_concepts.uri==myKey),]\n",
    "       \n",
    "    \n",
    "        #Filter the dataset using the Keyword to Map\n",
    "\n",
    "        df_items=udf_alprop.loc[(udf_alprop['concept.label'].str.lower()==uk.lower()), ]#& (udf_alprop['type.code'].str.lower()=='keyword')]\n",
    "        \n",
    "        #print (f' n. prop: {df_items.shape[0]}')\n",
    "        if (df_items.empty):\n",
    "            print (f\"\\n%%%%%%%%  No items found for {myKey}\")\n",
    "            continue;\n",
    "        print (f'&&&&&  Found as {df_items.iloc[0][\"type.code\"]}')\n",
    "        #update the MP\n",
    "        jsonConcept={}\n",
    "        jsonConceptVal={}\n",
    "    \n",
    "        jsonConceptVal[\"code\"]=df_mapto.iloc[0].code\n",
    "        jsonConceptVal[\"vocabulary\"]=df_mapto.iloc[0].vocabulary\n",
    "        jsonConceptVal[\"uri\"]=df_mapto.iloc[0].uri\n",
    "        #jsonConcept\n",
    "        \n",
    "        attrList={}\n",
    "        attrList[\"type\"]=df_mapto.iloc[0].types[0]\n",
    "        attrList[\"concept\"]=jsonConceptVal\n",
    "        jsonmapto.append(attrList)\n",
    "        filterList={}\n",
    "        filterList[\"concept\"]=uk.lower()\n",
    "    #print (f'update parameters: {jsonmapto} - {filterList} \\n')\n",
    "    #test['b'] = [[5, 6, 7]] * len(test)\n",
    "    df_items['updateList']=[jsonmapto] * len(df_items)\n",
    "    df_items['filterList']=[filterList] * len(df_items)\n",
    "    #df_items.loc[ : ,('updateList')]=[jsonmapto for _ in range(df_items.shape[0])]\n",
    "    #df_items.loc[ : ,('filterList')]=[filterList for _ in range(df_items.shape[0])]\n",
    "    \n",
    "    selectedItems=pd.concat([selectedItems, df_items.loc[df_items.astype(str).drop_duplicates(keep='first').index]])\n",
    "    \n",
    "\n",
    "attrList={}\n",
    "filterList={}\n",
    "#selectedItems.head()\n",
    "mpdata.updateItemsProperties(selectedItems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of 'Rejecting' keywords from the [gsheet](https://docs.google.com/spreadsheets/d/1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA'\n",
    "sheet_name = 'Rejecting'\n",
    "rejurl = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df_rej_keywords=pd.read_csv(rejurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rej_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "rejectedItems=pd.DataFrame()\n",
    "for rown, row in df_rej_keywords.iterrows():\n",
    "    \n",
    "    rk=df_rej_keywords.iloc[rown]['Keyword to reject']\n",
    "   \n",
    "    df_items_wrk=udf_alprop.loc[(udf_alprop['concept.label'].str.lower()==rk.lower()), ]\n",
    "        \n",
    "    if (df_items_wrk.empty):\n",
    "        print (f\"\\n%%%%%%%%  No items found for {rk}\")\n",
    "        continue;\n",
    "    print (f'&&&&&  Found as {df_items_wrk.iloc[0][\"type.code\"]}\\n')\n",
    "    jsonmapto=[]    \n",
    "    #attrList={}\n",
    "        \n",
    "    #jsonmapto.append(attrList)\n",
    "    filterList={}\n",
    "    filterList[\"concept\"]=rk.lower()\n",
    "    \n",
    "    df_items_wrk['filterList']=[filterList] * len(df_items_wrk)\n",
    "    df_items_wrk['updateList']=[jsonmapto] * len(df_items_wrk)\n",
    "    \n",
    "#     df_items_wrk.loc[ : ,('filterList')]=[filterList for _ in range(df_items_wrk.shape[0])]\n",
    "#     df_items_wrk.loc[ : ,('updateList')]=[jsonmapto for _ in range(df_items_wrk.shape[0])]\n",
    "    rejectedItems=pd.concat([rejectedItems, df_items_wrk.loc[df_items_wrk.astype(str).drop_duplicates(keep='first').index]])\n",
    "    \n",
    "\n",
    "attrList={}\n",
    "filterList={}\n",
    "#rejectedItems.head()\n",
    "mpdata.updateItemsProperties(rejectedItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
