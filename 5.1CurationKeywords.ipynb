{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5.1 - Curation-Keywords\n",
    "\n",
    "This notebook implements the workflow defined in:\n",
    "\n",
    "[Curating keywords](https://gitlab.gwdg.de/sshoc/marketplace-curation/-/issues/1#note_71056) GitLab issue\n",
    "\n",
    "The notebook works as follows:\n",
    "\n",
    "0. Imports external libraries and loads the MP dataset and the google sheet\n",
    "1. Updates keywords on MP as follows:\n",
    "    1. Looks for vocabulary terms with the value from the column *Keyword to map*\n",
    "    2. Looks for the term in the column *Map to*\n",
    "    3. Goes through all MP items to look for the *keywords-to-map* in the keyword-dynamic-property\n",
    "    4. Replaces the  the *keywords-to-map* in the MP dataset.\n",
    "2. Delete keywords marked as 'delete' in the gsheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Requirements to run this notebook\n",
    "\n",
    "This section gives all the relevant information to \"interact\" with the MP data.\n",
    "\n",
    "### 0.1 libraries\n",
    "*There are a number of external libraries needed to run the notebook* \n",
    "\n",
    "*Furthermore, a dedicated SSH Open Marketplace library - sshmarketplacelib - with customised functions has been created and can be imported using the python import commands.* \n",
    "\n",
    "*Below the libraries import needed to run this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "#import the MarketPlace Library \n",
    "from sshmarketplacelib import MPData as mpd\n",
    "from sshmarketplacelib import  eval as eva, helper as hel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Get the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the MarketPlace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data from local repository...\n",
      "getting data from local repository...\n",
      "getting data from local repository...\n",
      "getting data from local repository...\n",
      "getting data from local repository...\n"
     ]
    }
   ],
   "source": [
    "mpdata = mpd()\n",
    "df_tool_flat =mpdata.getMPItems (\"toolsandservices\", True)\n",
    "df_publication_flat =mpdata.getMPItems (\"publications\", True)\n",
    "df_trainingmaterials_flat =mpdata.getMPItems (\"trainingmaterials\", True)\n",
    "df_workflows_flat =mpdata.getMPItems (\"workflows\", True)\n",
    "df_datasets_flat =mpdata.getMPItems (\"datasets\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *getMPConcepts()* is a custom function that uses the API entry: \n",
    "\n",
    "GET https://marketplace-api.sshopencloud.eu/api/concept-search?perpage=100&q=URI\n",
    "\n",
    "to get all the *concepts* from the MarketPlace dataset. \n",
    "\n",
    "**Note that this function may require a long execution time**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts=mpdata.getMPConcepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils=hel.Util()\n",
    "resultfields=['persistentId', 'MPUrl', 'category', 'label', 'type.code', 'type.label', 'concept.code', 'concept.label', 'concept.uri', 'concept.vocabulary.scheme']\n",
    "udf_alprop=utils.getAllPropertiesBySources()\n",
    "udf_alprop=udf_alprop.loc[ : ,resultfields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_alprop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Update keywords\n",
    "\n",
    "The function *getMPKeywordProperties(mKey)* used below is a custum function that uses the API entry \n",
    "\n",
    "    GET https://marketplace-api.sshopencloud.eu/api/concept-search?types=keyword&q=VALUE\n",
    "\n",
    "and returns the vocabulary terms for *mKey*.  \n",
    "\n",
    "The returned dataset is filtered to individuate those values coming from the vocabulary *sshoc-keyword* (vocabulary[code]=sshoc-keyword).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of keywords from the [gsheet](https://docs.google.com/spreadsheets/d/1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sheet_id = '1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA'\n",
    "sheet_name = 'Mappings'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df_keywords=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords=df_keywords[df_keywords['Map to']!='delete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_keyword=df_keywords.groupby(['Keyword to map'])['Map to'].apply(list).reset_index(name='Maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "selectedItems=pd.DataFrame()\n",
    "df_items=pd.DataFrame()\n",
    "#df_vocterms=pd.DataFrame()\n",
    "for rown, row in df_grouped_keyword.iterrows():\n",
    "    \n",
    "#     uk=df_grouped_keyword.iloc[rown]['Keyword to map']\n",
    "#     myKeys=df_grouped_keyword.iloc[rown]['Maps']\n",
    "    uk=row['Keyword to map']\n",
    "    myKeys=row['Maps']\n",
    "    jsonmapto=[]\n",
    "    filterList={}\n",
    "    for myKey in myKeys:\n",
    "        myKey=myKey.strip()\n",
    "        #print(myKey)\n",
    "        if ('training-online_courses' in myKey):\n",
    "            continue;\n",
    "        df_vocterms=mpdata.getMPKeywordProperties(myKey)\n",
    "       \n",
    "        print(f'*****')\n",
    "        print(f' Checking {uk}, {myKey}')\n",
    "        if (df_vocterms.empty):\n",
    "            print (f\"#####  No vocabulary terms found for {myKey[0]}\")\n",
    "            continue;\n",
    "        df_vocterms.loc[:]=df_vocterms.loc[(df_vocterms.vocabulary=={'code': 'sshoc-keyword'}), ]\n",
    "    \n",
    "        #The set of vocabulary terms is filterd to individuate those with the exact match (case-insensitive) \n",
    "        df_vocterms=df_vocterms.loc[(df_vocterms.code).str.replace(' %3E ', ' > ').str.lower()==myKey.lower()]\n",
    "\n",
    "        #Search for the one concept that has in the uri column the value of the Map to. There should be only one such concept.\n",
    "    \n",
    "   \n",
    "        df_mapto=df_concepts.loc[(df_concepts.uri==myKey),]\n",
    "       \n",
    "        if (df_mapto.empty):\n",
    "            print (f\"\\n%%%%%%%%  No concept found for {myKey}\")\n",
    "            continue;\n",
    "        \n",
    "        #Filter the dataset using the Keyword to Map\n",
    "\n",
    "        df_items=udf_alprop.loc[(udf_alprop['concept.label'].str.lower()==uk.lower()), ]#& (udf_alprop['type.code'].str.lower()=='keyword')]\n",
    "        \n",
    "        #print (f' n. prop: {df_items.shape[0]}')\n",
    "        if (df_items.empty):\n",
    "            print (f\"\\n No items found for {myKey}\")\n",
    "            continue;\n",
    "        print (f'\\n Found as {df_items.iloc[0][\"type.code\"]} - in {df_items.shape[0]} items')\n",
    "        #update the MP\n",
    "        jsonConcept={}\n",
    "        jsonConceptVal={}\n",
    "    \n",
    "        jsonConceptVal[\"code\"]=df_mapto.iloc[0].code\n",
    "        jsonConceptVal[\"vocabulary\"]=df_mapto.iloc[0].vocabulary\n",
    "        jsonConceptVal[\"uri\"]=df_mapto.iloc[0].uri\n",
    "        #jsonConcept\n",
    "        \n",
    "        attrList={}\n",
    "        attrList[\"type\"]=df_mapto.iloc[0].types[0]\n",
    "        attrList[\"concept\"]=jsonConceptVal\n",
    "        jsonmapto.append(attrList)\n",
    "        filterList={}\n",
    "        filterList[\"concept\"]=uk.lower()\n",
    "    #print (f'update parameters: {jsonmapto} - {filterList} \\n')\n",
    "    #test['b'] = [[5, 6, 7]] * len(test)\n",
    "    if ((not df_items.empty) & len(filterList)>0):\n",
    "        if (len(filterList)==0):\n",
    "            print(f'&&&&&&&&&&&&&&&&& {jsonmapto}, {df_items.shape}')\n",
    "        df_items['updateList']=[jsonmapto] * len(df_items)\n",
    "        df_items['filterList']=[filterList] * len(df_items)\n",
    "        #df_items.loc[ : ,('updateList')]=[jsonmapto for _ in range(df_items.shape[0])]\n",
    "        #df_items.loc[ : ,('filterList')]=[filterList for _ in range(df_items.shape[0])]\n",
    "    \n",
    "        selectedItems=pd.concat([selectedItems, df_items.loc[df_items.astype(str).drop_duplicates(keep='first').index]])\n",
    "    \n",
    "\n",
    "attrList={}\n",
    "filterList={}\n",
    "#selectedItems.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedItems[selectedItems['concept.uri']=='https://vocabs.dariah.eu/tadirah/contentAnalysis'].head()\n",
    "selectedItems.iloc[510:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpdata.updateItemsProperties(selectedItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylog=mpdata._getLog()\n",
    "mylog.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Delete Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of keywords from the [gsheet](https://docs.google.com/spreadsheets/d/1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '1-Oh9_SxIhfMAT6KNJrMf4LetCpy5s1fHZEyTL__TUVA'\n",
    "sheet_name = 'Mappings'\n",
    "rejurl = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df_rej_keywords=pd.read_csv(rejurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rej_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword to map</th>\n",
       "      <th>Map to</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Discussion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...)</td>\n",
       "      <td>delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.NET</td>\n",
       "      <td>delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;a href=https://exmaralda.org/en/2018/11/26/ea...</td>\n",
       "      <td>delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;a href=https://www.unipotsdam.de/langage/laba...</td>\n",
       "      <td>delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-grams</td>\n",
       "      <td>delete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Keyword to map  Map to Comment  \\\n",
       "1                                               ...)  delete     NaN   \n",
       "2                                               .NET  delete     NaN   \n",
       "3  <a href=https://exmaralda.org/en/2018/11/26/ea...  delete     NaN   \n",
       "4  <a href=https://www.unipotsdam.de/langage/laba...  delete     NaN   \n",
       "5                                            1-grams  delete     NaN   \n",
       "\n",
       "  Discussion  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "5        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rej_keywords=df_rej_keywords[df_rej_keywords['Map to']=='delete'].drop_duplicates(keep='first')\n",
    "df_rej_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%%%%%%%%  No items found for ...)\n",
      "\n",
      "%%%%%%%%  No items found for .NET\n",
      "\n",
      "%%%%%%%%  No items found for <a href=https://exmaralda.org/en/2018/11/26/eadhworkshopannotationofdigitaloraldatacollectionsinthehumanitiesandsocialsciences3/>EXMARaLDA</a>\n",
      "\n",
      "%%%%%%%%  No items found for <a href=https://www.unipotsdam.de/langage/labank/ebay.php>see here</a>\n",
      "\n",
      "%%%%%%%%  No items found for 1-grams\n",
      "\n",
      "%%%%%%%%  No items found for 3:44 hours\n",
      "are glossed and about 1:45 hours are translated and glossed.\n",
      "\n",
      "%%%%%%%%  No items found for a few usage examples\n",
      "\n",
      "%%%%%%%%  No items found for a subset tagged for multiword expressions and semantic roles\n",
      "\n",
      "%%%%%%%%  No items found for a wide range of language characteristics that provide researchers with concrete examples of learner performance and progress across multiple proficiency levels.\n",
      "\n",
      "%%%%%%%%  No items found for AAH\n",
      "\n",
      "%%%%%%%%  No items found for abstracts\n",
      "\n",
      "%%%%%%%%  No items found for academia\n",
      "\n",
      "%%%%%%%%  No items found for activity - resource creation\n",
      "\n",
      "%%%%%%%%  No items found for agenda item metadata\n",
      "\n",
      "%%%%%%%%  No items found for airbnb\n",
      "\n",
      "%%%%%%%%  No items found for Alias StudioTools (.wire)\n",
      "\n",
      "%%%%%%%%  No items found for amazon\n",
      "\n",
      "%%%%%%%%  No items found for america\n",
      "\n",
      "%%%%%%%%  No items found for and more\n",
      "\n",
      "%%%%%%%%  No items found for Apache HTTP server\n",
      "\n",
      "%%%%%%%%  No items found for byu\n",
      "\n",
      "%%%%%%%%  No items found for CANEVAS Consortium-HN\n",
      "\n",
      "%%%%%%%%  No items found for cgi\n",
      "\n",
      "%%%%%%%%  No items found for CHM\n",
      "\n",
      "%%%%%%%%  No items found for COiNS\n",
      "\n",
      "%%%%%%%%  No items found for CommonCrawl\n",
      "\n",
      "%%%%%%%%  No items found for concept clarification in the case of homonymity in Greek\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN 3D-SHS\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN ARIANE\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN CORLI2\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN DISTAM\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN MASAplus\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN Musica2\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN pictorIA\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN Projets Time Machine\n",
      "\n",
      "%%%%%%%%  No items found for Consortium-HN Sounds of Life\n",
      "\n",
      "%%%%%%%%  No items found for cqp\n",
      "\n",
      "%%%%%%%%  No items found for Data\n",
      "\n",
      "%%%%%%%%  No items found for Data-Management, FAIR, Data publication, Data archive\n",
      "\n",
      "%%%%%%%%  No items found for DCX\n",
      "\n",
      "%%%%%%%%  No items found for descriptions and explanations of Slovenian phrasemes\n",
      "\n",
      "%%%%%%%%  No items found for DH Answers\n",
      "\n",
      "%%%%%%%%  No items found for DHCS\n",
      "\n",
      "%%%%%%%%  No items found for difficult to encode)\n",
      "\n",
      "%%%%%%%%  No items found for etc.)\n",
      "\n",
      "%%%%%%%%  No items found for Evernote\n",
      "\n",
      "%%%%%%%%  No items found for French and others\n",
      "\n",
      "%%%%%%%%  No items found for get-ready\n",
      "\n",
      "%%%%%%%%  No items found for github\n",
      "\n",
      "%%%%%%%%  No items found for google-books\n",
      "\n",
      "%%%%%%%%  No items found for gwt\n",
      "\n",
      "%%%%%%%%  No items found for http:/nanoc.stoneship.org/docs/\n",
      "\n",
      "%%%%%%%%  No items found for Inkscape\n",
      "\n",
      "%%%%%%%%  No items found for Kříže z Telče\n",
      "\n",
      "%%%%%%%%  No items found for leiden\n",
      "\n",
      "%%%%%%%%  No items found for Linux with a current Java runtime environment.\n",
      "\n",
      "%%%%%%%%  No items found for Linux/POSIX (C++)\n",
      "\n",
      "%%%%%%%%  No items found for Linux/POSIX (workflow itself runs on JVM\n",
      "\n",
      "%%%%%%%%  No items found for lynks\n",
      "\n",
      "%%%%%%%%  No items found for named entities; coreference annotation and annotation of spatial and temporal relations for the manually annotated SoNaR-1 subset\n",
      "\n",
      "%%%%%%%%  No items found for NER with entity linking (all functionality is derived from the individual parts rather than an inherent part of the workflow)\n",
      "\n",
      "%%%%%%%%  No items found for noaa\n",
      "\n",
      "%%%%%%%%  No items found for None\n",
      "\n",
      "%%%%%%%%  No items found for none\n",
      "\n",
      "%%%%%%%%  No items found for norwegian.norwegian\n",
      "\n",
      "%%%%%%%%  No items found for not annotated yet\n",
      "\n",
      "%%%%%%%%  No items found for Omeka\n",
      "\n",
      "%%%%%%%%  No items found for Other\n",
      "\n",
      "%%%%%%%%  No items found for others\n",
      "\n",
      "%%%%%%%%  No items found for PhotoShop\n",
      "\n",
      "%%%%%%%%  No items found for Preferred form\n",
      "\n",
      "%%%%%%%%  No items found for problem solving\n",
      "\n",
      "%%%%%%%%  No items found for QuarkXpress\n",
      "\n",
      "%%%%%%%%  No items found for roughly 3:52 hours are translated in English and Indonesian\n",
      "\n",
      "%%%%%%%%  No items found for Rules\n",
      "\n",
      "%%%%%%%%  No items found for SalesForce\n",
      "\n",
      "%%%%%%%%  No items found for see description\n",
      "\n",
      "%%%%%%%%  No items found for semantics and etymology of the words; for many unadapted foreign words the pronunciation is given\n",
      "\n",
      "%%%%%%%%  No items found for service - support service\n",
      "\n",
      "%%%%%%%%  No items found for Solr\n",
      "\n",
      "%%%%%%%%  No items found for Source code provided for Linux users\n",
      "\n",
      "%%%%%%%%  No items found for SpaCy\n",
      "\n",
      "%%%%%%%%  No items found for spc\n",
      "\n",
      "%%%%%%%%  No items found for Subset is manually annotated with speaker ID and time alignment\n",
      "\n",
      "%%%%%%%%  No items found for Sustainable\n",
      "\n",
      "%%%%%%%%  No items found for TextGrid\n",
      "\n",
      "%%%%%%%%  No items found for thomas-gray\n",
      "\n",
      "%%%%%%%%  No items found for TtT\n",
      "\n",
      "%%%%%%%%  No items found for Uncategorized\n",
      "\n",
      "%%%%%%%%  No items found for university\n",
      "\n",
      "%%%%%%%%  No items found for visual\n",
      "\n",
      "%%%%%%%%  No items found for what is knowledge based system\n",
      "\n",
      "%%%%%%%%  No items found for Windows (cut-down java version also available for other OS)\n",
      "\n",
      "%%%%%%%%  No items found for yes\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "rejectedItems=pd.DataFrame()\n",
    "for rown, row in df_rej_keywords.iterrows():\n",
    "    #print (row)\n",
    "    #rk=df_rej_keywords.iloc[rown]['Keyword to map']\n",
    "    rk=row['Keyword to map']\n",
    "    df_items_wrk=udf_alprop.loc[(udf_alprop['concept.label'].str.lower()==rk.lower()), ]\n",
    "        \n",
    "    if (df_items_wrk.empty):\n",
    "        print (f\"\\n%%%%%%%%  No items found for {rk}\")\n",
    "        continue;\n",
    "    print (f'\\n Keyword {rk} found as {df_items_wrk.iloc[0][\"type.code\"]}\\n')\n",
    "    jsonmapto=[]    \n",
    "    #attrList={}\n",
    "        \n",
    "    #jsonmapto.append(attrList)\n",
    "    filterList={}\n",
    "    filterList[\"concept\"]=rk.lower()\n",
    "    \n",
    "    df_items_wrk['filterList']=[filterList] * len(df_items_wrk)\n",
    "    df_items_wrk['updateList']=[jsonmapto] * len(df_items_wrk)\n",
    "    \n",
    "#     df_items_wrk.loc[ : ,('filterList')]=[filterList for _ in range(df_items_wrk.shape[0])]\n",
    "#     df_items_wrk.loc[ : ,('updateList')]=[jsonmapto for _ in range(df_items_wrk.shape[0])]\n",
    "    rejectedItems=pd.concat([rejectedItems, df_items_wrk.loc[df_items_wrk.astype(str).drop_duplicates(keep='first').index]])\n",
    "    \n",
    "\n",
    "attrList={}\n",
    "filterList={}\n",
    "#rejectedItems.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty data frame provided! No actions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpdata.updateItemsProperties(rejectedItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
